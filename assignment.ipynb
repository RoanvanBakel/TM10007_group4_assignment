{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "1d819bec0b8217398d74289d15bf4988d9b8c7fd3e8166b08890b7b304d8ca30"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcFlFpwRJlpP"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NE_fTbKGe5z",
        "outputId": "6f562fb7-8fc4-40fb-ae4c-fc9a46565af3"
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "#from adni.load_data import load_data\n",
        "#from brats.load_data import load_data\n",
        "#from hn.load_data import load_data\n",
        "from ecg.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 827\nThe number of columns: 9001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Ijcl2yJlpQ"
      },
      "source": [
        "# --------------\n",
        "# Data splitting\n",
        "# --------------\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "labels = data.pop('label')\n",
        "\n",
        "x, x_test, y, y_test = train_test_split (data, labels, test_size=0.2, train_size=0.8, stratify=True)\n",
        "\n",
        "# ---------------\n",
        "# Feature scaling\n",
        "# ---------------\n",
        "from sklearn.preprocessing import RobustScaler, QuantileTransformer\n",
        "scaler = RobustScaler() \n",
        "scaler.fit_transform(x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}