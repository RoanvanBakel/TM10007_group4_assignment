{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "1d819bec0b8217398d74289d15bf4988d9b8c7fd3e8166b08890b7b304d8ca30"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcFlFpwRJlpP"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NE_fTbKGe5z",
        "outputId": "6f562fb7-8fc4-40fb-ae4c-fc9a46565af3"
      },
      "source": [
        "'''\n",
        "This program runs a set of classifiers to determine predictions outcomes.\n",
        "A dataset of ECG features for multiple patients are used to score the prediction models.\n",
        "'''\n",
        "\n",
        "\n",
        "# Importing pandas and numpy for data processing and overall coding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Importing libraries for data splitting, feature selection, different classifiers,\n",
        "# and classification metrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.utils import parallel_backend\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing the load_data function from the ecg module\n",
        "from ecg.load_data import load_data\n",
        "\n",
        "\n",
        "# ----------------------------------\n",
        "# Data importing\n",
        "# ----------------------------------\n",
        "# Importing the ECG features dataset\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 827\nThe number of columns: 9001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Ijcl2yJlpQ"
      },
      "source": [
        "# -------------------------------------------------------------------------------------------\n",
        "# Data splitting\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# Data is split in training and test set, where the training set is 80% of the total dataset.\n",
        "# Split is stratified based on the given labels.\n",
        "labels = data.pop('label')\n",
        "x, x_test, y, y_test = train_test_split(data, labels, test_size=0.2, train_size=0.8,\n",
        "                                        stratify=labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# Upsampling\n",
        "# ------------------------------------------------------\n",
        "# Upsampling training data to achieve 50/50 label split.\n",
        "def upsampler(x, y):\n",
        "    df = pd.concat([x, y], axis=1)\n",
        "    df_majority = df[df.label == 0]\n",
        "    df_minority = df[df.label == 1]\n",
        "\n",
        "    df_minority_upsampled = resample(df_minority,\n",
        "                                    replace=True,\n",
        "                                    n_samples=len(df_majority.index),\n",
        "                                    random_state=123)\n",
        "\n",
        "    x = pd.concat([df_majority, df_minority_upsampled])\n",
        "    y = x.pop('label')\n",
        "\n",
        "    return x, y\n",
        "\n",
        "[x, y] = upsampler(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------\n",
        "# Feature scaling\n",
        "# ---------------\n",
        "from sklearn.preprocessing import RobustScaler, QuantileTransformer\n",
        "scaler = RobustScaler() \n",
        "scaler.fit_transform(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------------\n",
        "# Principal Component Analysis (PCA)\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Performing the PCA with a total number of components where the accumulated variance\n",
        "# sums up to at least 90%.\n",
        "pca = PCA(n_components=0.95)\n",
        "principal_components_train = pca.fit_transform(x)\n",
        "principal_components_test = pca.transform(x_test)\n",
        "\n",
        "x = pd.DataFrame(data=principal_components_train)\n",
        "x_test = pd.DataFrame(data=principal_components_test)\n",
        "y = y.values.tolist()\n",
        "y = pd.DataFrame(data=y, columns=['label'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Classifier\n",
        "# -----------------------------------------------------------------------------\n",
        "# A function is created to test and run multiple classifiers for the given data\n",
        "\n",
        "# Define classifier models\n",
        "svc_model = SVC(C=10)\n",
        "rfc_model = RandomForestClassifier(n_estimators=50)\n",
        "\n",
        "def fit_classifier(x_train, x_val_test, y_train, y_val_test):\n",
        "    '''\n",
        "    This function defines multiple classifiers.\n",
        "    All classifiers are created, fitted, and the predictions are captured.\n",
        "\n",
        "    arg1 = x_train, the training data\n",
        "    arg2 = x_val_test, the validation/test data\n",
        "    arg3 = y_train, the training labels\n",
        "    arg4 = y_val_test, the validation/test labels\n",
        "\n",
        "    return:\n",
        "    predictions, predictions\n",
        "    pred_accuracies, accurary scores\n",
        "    pred_metrics, multiple scoring values\n",
        "    '''\n",
        "\n",
        "    # Upsampling training data to achieve 50/50 label split\n",
        "    df = pd.concat([x_train, y_train], axis=1)\n",
        "    df_majority = df[df.label == 0]\n",
        "    df_minority = df[df.label == 1]\n",
        "\n",
        "    df_minority_upsampled = resample(df_minority,\n",
        "                                     replace=True,\n",
        "                                     n_samples=len(df_majority.index),\n",
        "                                     random_state=123)\n",
        "\n",
        "    x_train = pd.concat([df_majority, df_minority_upsampled])\n",
        "    y_train = x_train.pop('label')\n",
        "    svc_model.fit(x_train, y_train)\n",
        "    rfc_model.fit(x_train, y_train)\n",
        "\n",
        "    predictions = {}\n",
        "    predictions['SVC_prediction'] = svc_model.predict(x_val_test)\n",
        "    predictions['RFC_prediction'] = rfc_model.predict(x_val_test)\n",
        "\n",
        "    pred_accuracies = {}\n",
        "    for pred in predictions:\n",
        "        pred_accuracies[pred] = accuracy_score(predictions[pred], y_val_test)\n",
        "\n",
        "    pred_metrics = {}\n",
        "    for pred in predictions:\n",
        "        pred_metrics[pred] = classification_report(predictions[pred], y_val_test, zero_division=0)\n",
        "\n",
        "    return predictions, pred_accuracies, pred_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------------------------\n",
        "# K-fold Cross-validation\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "# K-fold cross-validation is performed to check for generalization performance of the classifiers.\n",
        "k = 10\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
        "all_pred_accuracies = {}\n",
        "for train_index, test_index in skf.split(x, y):\n",
        "    [predictions, pred_accuracies, pred_metrics] = fit_classifier(x.iloc[train_index],\n",
        "                                                                  x.iloc[test_index],\n",
        "                                                                  y.iloc[train_index],\n",
        "                                                                  y.iloc[test_index])\n",
        "\n",
        "    if all_pred_accuracies == {}:  # Initialize the dict that's going to hold all predictions\n",
        "        all_pred_accuracies = pred_accuracies.copy()\n",
        "        for pred_type in pred_accuracies:\n",
        "            # Convert dict items to list\n",
        "            all_pred_accuracies[pred_type] = [all_pred_accuracies[pred_type]]\n",
        "    else:\n",
        "        for pred_type in pred_accuracies:\n",
        "            # Add accuracy scores to all_predictions dict\n",
        "            all_pred_accuracies[pred_type].append(pred_accuracies[pred_type])\n",
        "\n",
        "boxplt = pd.DataFrame(all_pred_accuracies)\n",
        "\n",
        "sns.set(context='notebook', style='whitegrid', font_scale=2)\n",
        "\n",
        "\n",
        "# Plot the graph\n",
        "plot = sns.boxplot(data=boxplt, whis=np.inf, width=.18)\n",
        "plot.set(title='Boxplot of accuracy for SVM and RFC after cross-validation',\n",
        "         xlabel='Classifier', ylabel='Accuracy',)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(f'Average {k}-fold prediction accuracies:')\n",
        "for pred_type in all_pred_accuracies:\n",
        "    print(f'{pred_type}: {np.mean(all_pred_accuracies[pred_type])}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# Grid Search Optimization\n",
        "# ------------------------\n",
        "run_grid_search = False\n",
        "if run_grid_search:\n",
        "    def grid_search_opt(model, params):\n",
        "        '''\n",
        "        Performs a grid search optimization on the given model/classifier\n",
        "        using the given parameters.\n",
        "\n",
        "        Returns results as DataFrame\n",
        "        '''\n",
        "        search = GridSearchCV(\n",
        "            estimator=model, param_grid=params, scoring='accuracy', cv=3\n",
        "        )\n",
        "        with parallel_backend('threading'):\n",
        "            search.fit(x, y)\n",
        "\n",
        "        reg_results = pd.DataFrame(search.cv_results_)\n",
        "        reg_results = reg_results.sort_values(by=['rank_test_score'])\n",
        "        return reg_results\n",
        "\n",
        "    params_svc = {'C': [0.1, 1, 10],\n",
        "                  'degree': [2, 3, 4, 5],\n",
        "                  'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
        "    # Be mindful that the linear kernel takes a VERY long time to compute.\n",
        "\n",
        "    params_rfc = {'n_estimators': [10, 50, 100],\n",
        "                  'min_samples_split': [1.0, 2, 5]}  # Function requires 1.0 to be a float.\n",
        "\n",
        "    reg_results = grid_search_opt(svc_model, params_svc)\n",
        "    print(reg_results)\n",
        "\n",
        "    reg_results = grid_search_opt(rfc_model, params_rfc)\n",
        "    print(reg_results)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Final test on test dataset\n",
        "# --------------------------\n",
        "RUN_FINAL_TEST = True\n",
        "if RUN_FINAL_TEST:\n",
        "    [predictions, pred_accuracies, pred_metrics] = fit_classifier(x, x_test, y, y_test)\n",
        "\n",
        "    print('Prediction accuracies (test set):')\n",
        "    for prediction in pred_accuracies:\n",
        "        print(f'{prediction}: {pred_accuracies[prediction]}')\n",
        "\n",
        "    print('Prediction metrics (test set):')\n",
        "    for prediction in pred_metrics:\n",
        "        print(f'{prediction}: {pred_metrics[prediction]}')\n",
        "\n",
        "    plot_confusion_matrix(svc_model, x_test, y_test)\n",
        "    plt.show()\n",
        "    plot_confusion_matrix(rfc_model, x_test, y_test)\n",
        "    plt.show()\n"
      ]
    }
  ]
}